{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "\n",
       ".rendered_html\n",
       "{\n",
       "  color: #2C5494;\n",
       "  font-family: Ubuntu;\n",
       "  font-size: 140%;\n",
       "  line-height: 1.1;\n",
       "  margin: 0.5em 0;\n",
       "  }\n",
       "\n",
       ".talk_title\n",
       "{\n",
       "  color: #498AF3;\n",
       "  font-size: 250%;\n",
       "  font-weight:bold;\n",
       "  line-height: 1.2; \n",
       "  margin: 10px 50px 10px;\n",
       "  }\n",
       "\n",
       ".subtitle\n",
       "{\n",
       "  color: #386BBC;\n",
       "  font-size: 180%;\n",
       "  font-weight:bold;\n",
       "  line-height: 1.2; \n",
       "  margin: 20px 50px 20px;\n",
       "  }\n",
       "\n",
       ".slide-header, p.slide-header\n",
       "{\n",
       "  color: #498AF3;\n",
       "  font-size: 200%;\n",
       "  font-weight:bold;\n",
       "  margin: 0px 20px 10px;\n",
       "  page-break-before: always;\n",
       "  text-align: center;\n",
       "  }\n",
       "\n",
       ".rendered_html h1\n",
       "{\n",
       "  color: #498AF3;\n",
       "  line-height: 1.2; \n",
       "  margin: 0.15em 0em 0.5em;\n",
       "  page-break-before: always;\n",
       "  text-align: center;\n",
       "  }\n",
       "\n",
       "\n",
       ".rendered_html h2\n",
       "{ \n",
       "  color: #386BBC;\n",
       "  line-height: 1.2;\n",
       "  margin: 1.1em 0em 0.5em;\n",
       "  }\n",
       "\n",
       ".rendered_html h3\n",
       "{ \n",
       "  font-size: 100%;\n",
       "  line-height: 1.2;\n",
       "  margin: 1.1em 0em 0.5em;\n",
       "  }\n",
       "\n",
       ".rendered_html li\n",
       "{\n",
       "  line-height: 1.8;\n",
       "  }\n",
       "\n",
       ".text_cell .input_prompt .CodeMirror-lines .output_area pre\n",
       "{\n",
       "    font-family: \"Ubuntu\";\n",
       "    font-size: 130%;\n",
       "}\n",
       "\n",
       ".gap-above\n",
       "{\n",
       "  padding-top: 200px;\n",
       "  }\n",
       "\n",
       ".gap01\n",
       "{\n",
       "  padding-top: 10px;\n",
       "  }\n",
       "\n",
       ".gap05\n",
       "{\n",
       "  padding-top: 50px;\n",
       "  }\n",
       "\n",
       ".gap1\n",
       "{\n",
       "  padding-top: 100px;\n",
       "  }\n",
       "\n",
       ".gap2\n",
       "{\n",
       "  padding-top: 200px;\n",
       "  }\n",
       "\n",
       ".gap3\n",
       "{\n",
       "  padding-top: 300px;\n",
       "  }\n",
       "\n",
       ".emph\n",
       "{\n",
       "  color: #386BBC;\n",
       "  }\n",
       "\n",
       ".warn\n",
       "{\n",
       "  color: red;\n",
       "  }\n",
       "\n",
       ".center\n",
       "{\n",
       "  text-align: center;\n",
       "  }\n",
       "\n",
       ".nb_link\n",
       "{\n",
       "    padding-bottom: 0.5em;\n",
       "}\n",
       "\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run ../../python-seminar/DataFiles_and_Notebooks/talktools.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.evernote.com/l/AUV1r1xvhBdPF6lX-2SJLkO-vkkmCXEDrMwB/image.png\">\n",
    "http://www.slideshare.net/ManojitNandi/parallel-programming-in-python-speeding-up-your-analysis\n",
    "\n",
    "Remember, you can create (fork) many processes, which are copies of the original parent process (memory, data, state) and act independently of each other. To share data between them you have to explicitly do that within each process. The Pythonic way we do multiprocessing (creation of new processes, communication between processes) is with `multiprocessing`.\n",
    "\n",
    "*\"effectively side-stepping the Global Interpreter Lock by using subprocesses instead of threads. Due to this, the multiprocessing module allows the programmer to fully leverage multiple processors on a given machine. It runs on both Unix and Windows.\"*\n",
    "\n",
    "- https://docs.python.org/3/library/multiprocessing.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analog to `threading.Thread` is `multiprocessing.Process`. You should be able to do a drop-in replacement. Instead of `current_thread()` you'd use `os.getpid()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing multip.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile multip.py\n",
    "\n",
    "import multiprocessing\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import random\n",
    "\n",
    "\n",
    "root = logging.getLogger()\n",
    "root.handlers = []\n",
    "logging.basicConfig(level=logging.DEBUG, stream=sys.stdout,\n",
    "                    format='(%(threadName)-9s-pid %(process)d) %(message)s',)\n",
    "\n",
    "\n",
    "def worker(num):\n",
    "    \"\"\"thread worker function\"\"\"\n",
    "    \n",
    "    sleep_time = random.randint(1, 8)\n",
    "    logging.debug(f'worker: {num} sleeping for {sleep_time} s, pid: {os.getpid()}')\n",
    "    time.sleep(sleep_time)\n",
    "    logging.debug(f'done: worker: {num}')\n",
    "    return\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    procs = []\n",
    "    for i in range(2):\n",
    "        p = multiprocessing.Process(target=worker, args=(i,))\n",
    "        procs.append(p)\n",
    "        p.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(MainThread-pid 66646) worker: 1 sleeping for 6 s, pid: 66646\n",
      "(MainThread-pid 66645) worker: 0 sleeping for 4 s, pid: 66645\n",
      "(MainThread-pid 66645) done: worker: 0\n",
      "(MainThread-pid 66646) done: worker: 1\n",
      "CPU times: user 258 ms, sys: 67.2 ms, total: 325 ms\n",
      "Wall time: 6.31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!python multip.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your machine has multiple cores, these two processes may get run on those two separate cores, independently.\n",
    "\n",
    "You may need to share info between processes. You can do this, just like with Threads with `Queues`. You can also use the (UNIX-like) Pipe to have  two processes communicate with each other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing multip1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile multip1.py\n",
    "# https://docs.python.org/3/library/multiprocessing.html#exchanging-objects-between-processes\n",
    "from multiprocessing import Process, Pipe\n",
    "\n",
    "def f(conn):\n",
    "    conn.send([42, None, 'hello'])\n",
    "    conn.close()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parent_conn, child_conn = Pipe()\n",
    "    p = Process(target=f, args=(child_conn,))\n",
    "    p.start()\n",
    "    print(parent_conn.recv())   # prints \"[42, None, 'hello']\"\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42, None, 'hello']\n"
     ]
    }
   ],
   "source": [
    "%run multip1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using pools of workers (in separate processes) with multiprocessing `Pool.`\n",
    "\n",
    "https://docs.python.org/3.6/library/multiprocessing.html#using-a-pool-of-workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing g.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile g.py\n",
    "\n",
    "import time\n",
    "\n",
    "def g(x):\n",
    "    # domain specific stuff here!\n",
    "    time.sleep(0.2)\n",
    "    return x*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool \n",
    "from g import g\n",
    "\n",
    "pool = Pool(processes=10)     # start 4 worker processes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<multiprocessing.pool.Pool state=RUN pool_size=10>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.18 ms, sys: 2.29 ms, total: 5.46 ms\n",
      "Wall time: 219 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time pool.map(g, range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def g1(x):\n",
    "    # domain specific stuff here!\n",
    "    time.sleep(0.2)\n",
    "    return x*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.34 ms, sys: 2.94 ms, total: 5.28 ms\n",
      "Wall time: 2.05 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time list(map(g1, range(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 9 81 1 4 16 25 36 64 49 "
     ]
    }
   ],
   "source": [
    "# print same numbers in arbitrary order\n",
    "for i in pool.imap_unordered(g, range(10)):\n",
    "    print(i, sep=\" \", end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python is packaging (pickling) up your functions and sending them to different processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will fail...\n",
    "pool.map(lambda x: x**3, range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "# run only one process \"g(10)\" asynchronously \n",
    "result = pool.apply_async(g, [10])\n",
    "\n",
    "# prints \"100\" unless you timeout\n",
    "print(result.get(timeout=0.25)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<multiprocessing.pool.ApplyResult at 0x7fca000b8be0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "del pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing f.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile f.py\n",
    "def f(x): \n",
    "    return x*x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`It can take a long time to fork the processes so unless you're running something longer than it takes to fork the processes, it doesn't make sense to use much more processes than # of cores`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 *****\n",
      "1.8884 sec\n",
      "2 *****\n",
      "1.2854 sec\n",
      "3 *****\n",
      "1.1321 sec\n",
      "4 *****\n",
      "1.1263 sec\n",
      "8 *****\n",
      "1.0422 sec\n",
      "16 *****\n",
      "0.9532 sec\n",
      "32 *****\n",
      "0.9983 sec\n",
      "64 *****\n",
      "0.9792 sec\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool \n",
    "import time\n",
    "\n",
    "from f import f\n",
    "\n",
    "for i in [1, 2, 3, 4, 8, 16, 32, 64]:\n",
    "    print(i,\"*\"*5, flush=True)\n",
    "    pool = Pool(processes=i)               # start 4 worker processes \n",
    "    start = time.time()\n",
    "    pool.map(f, range(10000000))\n",
    "    print(\"{0:0.4f} sec\".format(time.time() - start))\n",
    "    pool.terminate()\n",
    "    del pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-t: cpu time (seconds)              unlimited\r\n",
      "-f: file size (blocks)              unlimited\r\n",
      "-d: data seg size (kbytes)          unlimited\r\n",
      "-s: stack size (kbytes)             8176\r\n",
      "-c: core file size (blocks)         0\r\n",
      "-v: address space (kbytes)          unlimited\r\n",
      "-l: locked-in-memory size (kbytes)  unlimited\r\n",
      "-u: processes                       5333\r\n",
      "-n: file descriptors                4096\r\n"
     ]
    }
   ],
   "source": [
    "!ulimit -a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Launching parallel tasks with `concurrent.futures`\n",
    "\n",
    "Built-in, create different pools for executing **maps** (single loop over data). Local resources.\n",
    "\n",
    "<i>\"The `concurrent.futures` module provides a high-level interface for asynchronously executing callables.\n",
    "\n",
    "The asynchronous execution can be performed with threads, using `ThreadPoolExecutor`, or separate processes, using `ProcessPoolExecutor`. Both implement the same interface, which is defined by the abstract Executor class.\"</i>\n",
    "\n",
    "https://docs.python.org/3/library/concurrent.futures.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "e = ProcessPoolExecutor(2)  # can also use a threadpool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.16 ms, sys: 3.26 ms, total: 6.41 ms\n",
      "Wall time: 8.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "from time import sleep\n",
    "\n",
    "results = []\n",
    "for i in range(8):\n",
    "    sleep(1)\n",
    "    results.append(i + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting slow.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile slow.py\n",
    "from time import sleep, time\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "e = ProcessPoolExecutor() \n",
    "\n",
    "def slowfunc(x):\n",
    "    sleep(1)\n",
    "    return(x+1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    s = time()\n",
    "    results = list(e.map(slowfunc, range(8)))\n",
    "    print(f\"Finished in {time() - s:0.3f} sec\")\n",
    "    print(results)\n",
    "    \n",
    "    e.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in 1.099 sec\r\n",
      "[1, 2, 3, 4, 5, 6, 7, 8]\r\n"
     ]
    }
   ],
   "source": [
    "!python slow.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figured out I have 4 cores and ran it in 4 separate processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breakout\n",
    "\n",
    "Convert the sequential code to parallel using `concurrent.futures`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting fast.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile fast.py\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/Special:Random\"\n",
    "\n",
    "def run():\n",
    "    \"\"\"worker function\"\"\"\n",
    "    \n",
    "    resp = requests.get(url).text\n",
    "    title = BeautifulSoup(resp, 'html.parser').title.string.split('- Wikipedia')[0]\n",
    "    return len(title)\n",
    "\n",
    "\n",
    "e = ProcessPoolExecutor()\n",
    "lens = list(e.map(run,range(10)))\n",
    "print(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"<string>\", line 1, in <module>\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\r\n",
      "    exitcode = _main(fd, parent_sentinel)\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/multiprocessing/spawn.py\", line 125, in _main\r\n",
      "    prepare(preparation_data)\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/multiprocessing/spawn.py\", line 236, in prepare\r\n",
      "    _fixup_main_from_path(data['init_main_from_path'])\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/multiprocessing/spawn.py\", line 287, in _fixup_main_from_path\r\n",
      "    main_content = runpy.run_path(main_path,\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/runpy.py\", line 268, in run_path\r\n",
      "    return _run_module_code(code, init_globals, run_name,\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/runpy.py\", line 97, in _run_module_code\r\n",
      "    _run_code(code, mod_globals, init_globals,\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/runpy.py\", line 87, in _run_code\r\n",
      "    exec(code, run_globals)\r\n",
      "  File \"/Users/alizabeverage/Class/python-ay250-homework/lecture4_parallelism/fast.py\", line 17, in <module>\r\n",
      "    lens = list(e.map(run,range(10)))\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/concurrent/futures/process.py\", line 726, in map\r\n",
      "    results = super().map(partial(_process_chunk, fn),\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py\", line 597, in map\r\n",
      "    fs = [self.submit(fn, *args) for args in zip(*iterables)]\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py\", line 597, in <listcomp>\r\n",
      "    fs = [self.submit(fn, *args) for args in zip(*iterables)]\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/concurrent/futures/process.py\", line 697, in submit\r\n",
      "    self._adjust_process_count()\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/concurrent/futures/process.py\", line 675, in _adjust_process_count\r\n",
      "    p.start()\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 121, in start\r\n",
      "    self._popen = self._Popen(self)\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/multiprocessing/context.py\", line 284, in _Popen\r\n",
      "    return Popen(process_obj)\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/multiprocessing/popen_spawn_posix.py\", line 32, in __init__\r\n",
      "    super().__init__(process_obj)\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/multiprocessing/popen_fork.py\", line 19, in __init__\r\n",
      "    self._launch(process_obj)\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/multiprocessing/popen_spawn_posix.py\", line 42, in _launch\r\n",
      "    prep_data = spawn.get_preparation_data(process_obj._name)\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/multiprocessing/spawn.py\", line 154, in get_preparation_data\r\n",
      "    _check_not_importing_main()\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/multiprocessing/spawn.py\", line 134, in _check_not_importing_main\r\n",
      "    raise RuntimeError('''\r\n",
      "RuntimeError: \r\n",
      "        An attempt has been made to start a new process before the\r\n",
      "        current process has finished its bootstrapping phase.\r\n",
      "\r\n",
      "        This probably means that you are not using fork to start your\r\n",
      "        child processes and you have forgotten to use the proper idiom\r\n",
      "        in the main module:\r\n",
      "\r\n",
      "            if __name__ == '__main__':\r\n",
      "                freeze_support()\r\n",
      "                ...\r\n",
      "\r\n",
      "        The \"freeze_support()\" line can be omitted if the program\r\n",
      "        is not going to be frozen to produce an executable.\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"<string>\", line 1, in <module>\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\r\n",
      "    exitcode = _main(fd, parent_sentinel)\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/multiprocessing/spawn.py\", line 125, in _main\r\n",
      "    prepare(preparation_data)\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/multiprocessing/spawn.py\", line 236, in prepare\r\n",
      "    _fixup_main_from_path(data['init_main_from_path'])\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/multiprocessing/spawn.py\", line 287, in _fixup_main_from_path\r\n",
      "    main_content = runpy.run_path(main_path,\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/runpy.py\", line 268, in run_path\r\n",
      "    return _run_module_code(code, init_globals, run_name,\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/runpy.py\", line 97, in _run_module_code\r\n",
      "    _run_code(code, mod_globals, init_globals,\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/runpy.py\", line 87, in _run_code\r\n",
      "    exec(code, run_globals)\r\n",
      "  File \"/Users/alizabeverage/Class/python-ay250-homework/lecture4_parallelism/fast.py\", line 17, in <module>\r\n",
      "    lens = list(e.map(run,range(10)))\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/concurrent/futures/process.py\", line 726, in map\r\n",
      "    results = super().map(partial(_process_chunk, fn),\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py\", line 597, in map\r\n",
      "    fs = [self.submit(fn, *args) for args in zip(*iterables)]\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py\", line 597, in <listcomp>\r\n",
      "    fs = [self.submit(fn, *args) for args in zip(*iterables)]\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/concurrent/futures/process.py\", line 697, in submit\r\n",
      "    self._adjust_process_count()\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/concurrent/futures/process.py\", line 675, in _adjust_process_count\r\n",
      "    p.start()\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 121, in start\r\n",
      "    self._popen = self._Popen(self)\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/multiprocessing/context.py\", line 284, in _Popen\r\n",
      "    return Popen(process_obj)\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/multiprocessing/popen_spawn_posix.py\", line 32, in __init__\r\n",
      "    super().__init__(process_obj)\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/multiprocessing/popen_fork.py\", line 19, in __init__\r\n",
      "    self._launch(process_obj)\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/multiprocessing/popen_spawn_posix.py\", line 42, in _launch\r\n",
      "    prep_data = spawn.get_preparation_data(process_obj._name)\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/multiprocessing/spawn.py\", line 154, in get_preparation_data\r\n",
      "    _check_not_importing_main()\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/multiprocessing/spawn.py\", line 134, in _check_not_importing_main\r\n",
      "    raise RuntimeError('''\r\n",
      "RuntimeError: \r\n",
      "        An attempt has been made to start a new process before the\r\n",
      "        current process has finished its bootstrapping phase.\r\n",
      "\r\n",
      "        This probably means that you are not using fork to start your\r\n",
      "        child processes and you have forgotten to use the proper idiom\r\n",
      "        in the main module:\r\n",
      "\r\n",
      "            if __name__ == '__main__':\r\n",
      "                freeze_support()\r\n",
      "                ...\r\n",
      "\r\n",
      "        The \"freeze_support()\" line can be omitted if the program\r\n",
      "        is not going to be frozen to produce an executable.\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"<string>\", line 1, in <module>\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"<string>\", line 1, in <module>\r\n",
      "    exitcode = _main(fd, parent_sentinel)\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/multiprocessing/spawn.py\", line 125, in _main\r\n",
      "    prepare(preparation_data)\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/multiprocessing/spawn.py\", line 236, in prepare\r\n",
      "    _fixup_main_from_path(data['init_main_from_path'])\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/multiprocessing/spawn.py\", line 287, in _fixup_main_from_path\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\r\n",
      "    main_content = runpy.run_path(main_path,\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/runpy.py\", line 268, in run_path\r\n",
      "    return _run_module_code(code, init_globals, run_name,\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/runpy.py\", line 97, in _run_module_code\r\n",
      "    _run_code(code, mod_globals, init_globals,\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/runpy.py\", line 87, in _run_code\r\n",
      "    exec(code, run_globals)\r\n",
      "  File \"/Users/alizabeverage/Class/python-ay250-homework/lecture4_parallelism/fast.py\", line 17, in <module>\r\n",
      "    lens = list(e.map(run,range(10)))\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/concurrent/futures/process.py\", line 726, in map\r\n",
      "    exitcode = _main(fd, parent_sentinel)\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/multiprocessing/spawn.py\", line 125, in _main\r\n",
      "    results = super().map(partial(_process_chunk, fn),\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py\", line 597, in map\r\n",
      "    fs = [self.submit(fn, *args) for args in zip(*iterables)]\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py\", line 597, in <listcomp>\r\n",
      "    prepare(preparation_data)\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/multiprocessing/spawn.py\", line 236, in prepare\r\n",
      "    _fixup_main_from_path(data['init_main_from_path'])\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/multiprocessing/spawn.py\", line 287, in _fixup_main_from_path\r\n",
      "    main_content = runpy.run_path(main_path,\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/runpy.py\", line 268, in run_path\r\n",
      "    return _run_module_code(code, init_globals, run_name,\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/runpy.py\", line 97, in _run_module_code\r\n",
      "    _run_code(code, mod_globals, init_globals,\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/runpy.py\", line 87, in _run_code\r\n",
      "    exec(code, run_globals)\r\n",
      "  File \"/Users/alizabeverage/Class/python-ay250-homework/lecture4_parallelism/fast.py\", line 17, in <module>\r\n",
      "    lens = list(e.map(run,range(10)))\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/concurrent/futures/process.py\", line 726, in map\r\n",
      "    fs = [self.submit(fn, *args) for args in zip(*iterables)]\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/concurrent/futures/process.py\", line 697, in submit\r\n",
      "    results = super().map(partial(_process_chunk, fn),\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py\", line 597, in map\r\n",
      "    fs = [self.submit(fn, *args) for args in zip(*iterables)]\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py\", line 597, in <listcomp>\r\n",
      "    fs = [self.submit(fn, *args) for args in zip(*iterables)]\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/concurrent/futures/process.py\", line 697, in submit\r\n",
      "    self._adjust_process_count()\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/concurrent/futures/process.py\", line 675, in _adjust_process_count\r\n",
      "    self._adjust_process_count()\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/concurrent/futures/process.py\", line 675, in _adjust_process_count\r\n",
      "    p.start()\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 121, in start\r\n",
      "    p.start()\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 121, in start\r\n",
      "    self._popen = self._Popen(self)\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/multiprocessing/context.py\", line 284, in _Popen\r\n",
      "    self._popen = self._Popen(self)\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/multiprocessing/context.py\", line 284, in _Popen\r\n",
      "    return Popen(process_obj)\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/multiprocessing/popen_spawn_posix.py\", line 32, in __init__\r\n",
      "    super().__init__(process_obj)\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/multiprocessing/popen_fork.py\", line 19, in __init__\r\n",
      "    self._launch(process_obj)\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/multiprocessing/popen_spawn_posix.py\", line 42, in _launch\r\n",
      "    prep_data = spawn.get_preparation_data(process_obj._name)\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/multiprocessing/spawn.py\", line 154, in get_preparation_data\r\n",
      "    _check_not_importing_main()\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/multiprocessing/spawn.py\", line 134, in _check_not_importing_main\r\n",
      "    raise RuntimeError('''\r\n",
      "RuntimeError: \r\n",
      "        An attempt has been made to start a new process before the\r\n",
      "        current process has finished its bootstrapping phase.\r\n",
      "\r\n",
      "        This probably means that you are not using fork to start your\r\n",
      "        child processes and you have forgotten to use the proper idiom\r\n",
      "        in the main module:\r\n",
      "\r\n",
      "            if __name__ == '__main__':\r\n",
      "                freeze_support()\r\n",
      "                ...\r\n",
      "\r\n",
      "        The \"freeze_support()\" line can be omitted if the program\r\n",
      "        is not going to be frozen to produce an executable.\r\n",
      "    return Popen(process_obj)\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/multiprocessing/popen_spawn_posix.py\", line 32, in __init__\r\n",
      "    super().__init__(process_obj)\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/multiprocessing/popen_fork.py\", line 19, in __init__\r\n",
      "    self._launch(process_obj)\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/multiprocessing/popen_spawn_posix.py\", line 42, in _launch\r\n",
      "    prep_data = spawn.get_preparation_data(process_obj._name)\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/multiprocessing/spawn.py\", line 154, in get_preparation_data\r\n",
      "    _check_not_importing_main()\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/multiprocessing/spawn.py\", line 134, in _check_not_importing_main\r\n",
      "    raise RuntimeError('''\r\n",
      "RuntimeError: \r\n",
      "        An attempt has been made to start a new process before the\r\n",
      "        current process has finished its bootstrapping phase.\r\n",
      "\r\n",
      "        This probably means that you are not using fork to start your\r\n",
      "        child processes and you have forgotten to use the proper idiom\r\n",
      "        in the main module:\r\n",
      "\r\n",
      "            if __name__ == '__main__':\r\n",
      "                freeze_support()\r\n",
      "                ...\r\n",
      "\r\n",
      "        The \"freeze_support()\" line can be omitted if the program\r\n",
      "        is not going to be frozen to produce an executable.\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"<string>\", line 1, in <module>\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\r\n",
      "    exitcode = _main(fd, parent_sentinel)\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/multiprocessing/spawn.py\", line 125, in _main\r\n",
      "    prepare(preparation_data)\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/multiprocessing/spawn.py\", line 236, in prepare\r\n",
      "    _fixup_main_from_path(data['init_main_from_path'])\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/multiprocessing/spawn.py\", line 287, in _fixup_main_from_path\r\n",
      "    main_content = runpy.run_path(main_path,\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/runpy.py\", line 268, in run_path\r\n",
      "    return _run_module_code(code, init_globals, run_name,\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/runpy.py\", line 97, in _run_module_code\r\n",
      "    _run_code(code, mod_globals, init_globals,\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/runpy.py\", line 87, in _run_code\r\n",
      "    exec(code, run_globals)\r\n",
      "  File \"/Users/alizabeverage/Class/python-ay250-homework/lecture4_parallelism/fast.py\", line 17, in <module>\r\n",
      "    lens = list(e.map(run,range(10)))\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/concurrent/futures/process.py\", line 726, in map\r\n",
      "    results = super().map(partial(_process_chunk, fn),\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py\", line 597, in map\r\n",
      "    fs = [self.submit(fn, *args) for args in zip(*iterables)]\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py\", line 597, in <listcomp>\r\n",
      "    fs = [self.submit(fn, *args) for args in zip(*iterables)]\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/concurrent/futures/process.py\", line 697, in submit\r\n",
      "    self._adjust_process_count()\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/concurrent/futures/process.py\", line 675, in _adjust_process_count\r\n",
      "    p.start()\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 121, in start\r\n",
      "    self._popen = self._Popen(self)\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/multiprocessing/context.py\", line 284, in _Popen\r\n",
      "    return Popen(process_obj)\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/multiprocessing/popen_spawn_posix.py\", line 32, in __init__\r\n",
      "    super().__init__(process_obj)\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/multiprocessing/popen_fork.py\", line 19, in __init__\r\n",
      "    self._launch(process_obj)\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/multiprocessing/popen_spawn_posix.py\", line 42, in _launch\r\n",
      "    prep_data = spawn.get_preparation_data(process_obj._name)\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/multiprocessing/spawn.py\", line 154, in get_preparation_data\r\n",
      "    _check_not_importing_main()\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/multiprocessing/spawn.py\", line 134, in _check_not_importing_main\r\n",
      "    raise RuntimeError('''\r\n",
      "RuntimeError: \r\n",
      "        An attempt has been made to start a new process before the\r\n",
      "        current process has finished its bootstrapping phase.\r\n",
      "\r\n",
      "        This probably means that you are not using fork to start your\r\n",
      "        child processes and you have forgotten to use the proper idiom\r\n",
      "        in the main module:\r\n",
      "\r\n",
      "            if __name__ == '__main__':\r\n",
      "                freeze_support()\r\n",
      "                ...\r\n",
      "\r\n",
      "        The \"freeze_support()\" line can be omitted if the program\r\n",
      "        is not going to be frozen to produce an executable.\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/Users/alizabeverage/Class/python-ay250-homework/lecture4_parallelism/fast.py\", line 17, in <module>\r\n",
      "    lens = list(e.map(run,range(10)))\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/concurrent/futures/process.py\", line 559, in _chain_from_iterable_of_lists\r\n",
      "    for element in iterable:\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py\", line 608, in result_iterator\r\n",
      "    yield fs.pop().result()\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py\", line 445, in result\r\n",
      "    return self.__get_result()\r\n",
      "  File \"/Users/alizabeverage/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py\", line 390, in __get_result\r\n",
      "    raise self._exception\r\n",
      "concurrent.futures.process.BrokenProcessPool: A process in the process pool was terminated abruptly while the future was running or pending.\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.6 ms, sys: 28.4 ms, total: 41 ms\n",
      "Wall time: 631 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!python fast.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executor.submit\n",
    "\n",
    "`submit` starts an execution in a separate thread or process and immediately returns a `Future` object that points back to the result. Until the function completes, the future is pending. We get the result of a task with `.result()`, which blocks until the computation is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing slowfunc.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile slowfunc.py\n",
    "from time import sleep\n",
    "\n",
    "def slowfunc(x, y, delay=1):\n",
    "    sleep(delay)\n",
    "    return(x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.76 ms, sys: 17 ms, total: 24.8 ms\n",
      "Wall time: 27.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "e = ProcessPoolExecutor() \n",
    "\n",
    "from slowfunc import slowfunc\n",
    "\n",
    "future = e.submit(slowfunc, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Future at 0x7fca496cbbb0 state=running>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.6 ms, sys: 99 ms, total: 123 ms\n",
      "Wall time: 1.18 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "futures = [e.submit(slowfunc,1,2, delay=1) for _ in range(10)]\n",
    "results = [f.result() for f in futures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joblib\n",
    "\n",
    "http://pythonhosted.org/joblib/\n",
    "\n",
    "Running Python functions as pipeline jobs. The *vision is to provide tools to easily achieve better performance and reproducibility when working with long running jobs.* Specifically meant to work well with large data (ie. numpy arrays)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - **Avoid computing twice the same thing**: code is rerun over an over, for instance when prototyping computational-heavy jobs (as in scientific development), but hand-crafted solution to alleviate this issue is error-prone and often leads to unreproducible results\n",
    "  - **Persist to disk transparently**: persisting in an efficient way arbitrary objects containing large data is hard. Using joblib’s caching mechanism avoids hand-written persistence and implicitly links the file on disk to the execution context of the original Python object. As a result, joblib’s persistence is good for resuming an application status or computational job, eg after a crash.\n",
    "\n",
    "Joblib strives to address these problems while leaving your code and your flow control as unmodified as possible (no framework, no new paradigms)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install joblib -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "[sqrt(i ** 2) for i in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel Helpers\n",
    "\n",
    "Joblib provides a simple helper class to write parallel for loops using multiprocessing. The core idea is to write the code to be executed as a generator expression, and convert it to parallel computing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default Parallel uses the Python multiprocessing module to fork separate Python worker processes to execute tasks concurrently on separate CPUs. This is a reasonable default for generic Python programs but it induces some overhead as the input and output data need to be serialized in a queue for communication with the worker processes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Parallel(n_jobs=2,backend=\"threading\") \\\n",
    "  (delayed(sqrt)(i ** 2) for i in range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "Parallel(n_jobs=5,verbose=5) \\\n",
    "  (delayed(time.sleep)(1) for _ in range(10))\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On demand recomputing: the `Memory` class\n",
    "\n",
    "Caching long running results so it can be reused. Let's try to cache to disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Memory\n",
    "memory = Memory(location=\"/tmp/\", verbose=0)  # try a higher verbosity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@memory.cache\n",
    "def f(x):\n",
    "    print('Running f(%s)' % x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lat  /tmp/joblib/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = Memory(location=\"/tmp/\",verbose=0, mmap_mode=\"r+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@memory.cache\n",
    "def josh(x,blah=True):\n",
    "    print('Running josh(%s)' % x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(josh(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(josh(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(josh(1, blah=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ignoring variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@memory.cache(ignore=['blah'])\n",
    "def h(x,blah=True):\n",
    "    print('Running h(%s)' % x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(h(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(h(1,blah=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: joblib also gives (for persistence) `joblib.dump()` and `joblib.load()` provide a replacement for pickle to work efficiently on Python objects containing large data, in particular large numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
