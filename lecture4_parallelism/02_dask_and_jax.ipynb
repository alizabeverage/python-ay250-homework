{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "\n",
       ".rendered_html\n",
       "{\n",
       "  color: #2C5494;\n",
       "  font-family: Ubuntu;\n",
       "  font-size: 140%;\n",
       "  line-height: 1.1;\n",
       "  margin: 0.5em 0;\n",
       "  }\n",
       "\n",
       ".talk_title\n",
       "{\n",
       "  color: #498AF3;\n",
       "  font-size: 250%;\n",
       "  font-weight:bold;\n",
       "  line-height: 1.2; \n",
       "  margin: 10px 50px 10px;\n",
       "  }\n",
       "\n",
       ".subtitle\n",
       "{\n",
       "  color: #386BBC;\n",
       "  font-size: 180%;\n",
       "  font-weight:bold;\n",
       "  line-height: 1.2; \n",
       "  margin: 20px 50px 20px;\n",
       "  }\n",
       "\n",
       ".slide-header, p.slide-header\n",
       "{\n",
       "  color: #498AF3;\n",
       "  font-size: 200%;\n",
       "  font-weight:bold;\n",
       "  margin: 0px 20px 10px;\n",
       "  page-break-before: always;\n",
       "  text-align: center;\n",
       "  }\n",
       "\n",
       ".rendered_html h1\n",
       "{\n",
       "  color: #498AF3;\n",
       "  line-height: 1.2; \n",
       "  margin: 0.15em 0em 0.5em;\n",
       "  page-break-before: always;\n",
       "  text-align: center;\n",
       "  }\n",
       "\n",
       "\n",
       ".rendered_html h2\n",
       "{ \n",
       "  color: #386BBC;\n",
       "  line-height: 1.2;\n",
       "  margin: 1.1em 0em 0.5em;\n",
       "  }\n",
       "\n",
       ".rendered_html h3\n",
       "{ \n",
       "  font-size: 100%;\n",
       "  line-height: 1.2;\n",
       "  margin: 1.1em 0em 0.5em;\n",
       "  }\n",
       "\n",
       ".rendered_html li\n",
       "{\n",
       "  line-height: 1.8;\n",
       "  }\n",
       "\n",
       ".text_cell .input_prompt .CodeMirror-lines .output_area pre\n",
       "{\n",
       "    font-family: \"Ubuntu\";\n",
       "    font-size: 130%;\n",
       "}\n",
       "\n",
       ".gap-above\n",
       "{\n",
       "  padding-top: 200px;\n",
       "  }\n",
       "\n",
       ".gap01\n",
       "{\n",
       "  padding-top: 10px;\n",
       "  }\n",
       "\n",
       ".gap05\n",
       "{\n",
       "  padding-top: 50px;\n",
       "  }\n",
       "\n",
       ".gap1\n",
       "{\n",
       "  padding-top: 100px;\n",
       "  }\n",
       "\n",
       ".gap2\n",
       "{\n",
       "  padding-top: 200px;\n",
       "  }\n",
       "\n",
       ".gap3\n",
       "{\n",
       "  padding-top: 300px;\n",
       "  }\n",
       "\n",
       ".emph\n",
       "{\n",
       "  color: #386BBC;\n",
       "  }\n",
       "\n",
       ".warn\n",
       "{\n",
       "  color: red;\n",
       "  }\n",
       "\n",
       ".center\n",
       "{\n",
       "  text-align: center;\n",
       "  }\n",
       "\n",
       ".nb_link\n",
       "{\n",
       "    padding-bottom: 0.5em;\n",
       "}\n",
       "\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run ../talktools.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://dask.readthedocs.io/en/latest/_images/dask_horizontal.svg\"\n",
    "     align=\"right\"\n",
    "     width=\"30%\"\n",
    "     alt=\"Dask logo\">\n",
    "     \n",
    "# Dask \n",
    "\n",
    "Dask is a parallelization library for Python that works on your laptop all the way to cluster-scale (ie. distributed multi-node)\n",
    "\n",
    "Main focus on creating distributed array-like abstraction: Numpy- and Pandas-like behavior.\n",
    "\n",
    "Stack:\n",
    "\n",
    "- Array, bag, dataframe, delayed\n",
    "- Graph spec\n",
    "- Scheduler\n",
    "\n",
    "Let's you focus on algorithms and not scheduling.\n",
    "\n",
    "Tutorial: https://github.com/dask/dask-tutorial\n",
    "\n",
    "See also some amazing new lectures/tutorials:\n",
    "\n",
    "https://www.youtube.com/watch?v=5Md_sSsN51k&list=PLYx7XA2nY5Gf37zYZMw6OqGFRPjB1jCy6&index=17\n",
    "\n",
    "and a shorter talk by Matt on Dask:\n",
    "\n",
    "https://www.youtube.com/watch?v=PAGjm4BMKlk&list=PLYx7XA2nY5Gf37zYZMw6OqGFRPjB1jCy6&index=16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    IPython (via <a href=\"https://github.com/ipython/ipyparallel\">ipyparallel</a>) also has a clustering mechanism for distribution computing. See e.g. <a href=\"https://ipyparallel.readthedocs.io/en/latest/examples/Monitoring%20an%20MPI%20Simulation%20-%202.html?highlight=mpi\">ipyparallel with MPI</a>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!brew install graphviz ## on a mac\n",
    "#!apt-get install graphviz ## on linux\n",
    "#!pip install graphviz ## dont do this with conda, installs a Python 2 package..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dask Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distributed notion of an array. `Dask.array` translates your array operations into a graph of inter-related tasks with data dependencies between them. Dask then executes this graph in parallel with multiple threads. We'll discuss more about this in the next section.\n",
    "\n",
    "Manipulate `dask.array` object as you would a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "x = da.linspace(1,10,1000000,chunks=(1000,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y = np.linspace(1,10,1000000)\n",
    "sum(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rez = x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rez.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dask.array as da\n",
    "\n",
    "x = da.random.normal(10, 0.1, size=(20000, 20000),   # 400 million element array \n",
    "                              chunks=(1000, 1000))   # Cut into 1000x1000 sized chunks\n",
    "y = x.mean(axis=0)[::100]                            # Perform NumPy-style operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.nbytes / 1e9  # Gigabytes of the input processed lazily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "y.compute()     # Time to compute the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# this will take AWHILE (~30 sec)\n",
    "x = np.random.normal(10, 0.1, size=(20000, 20000)) \n",
    "y = x.mean(axis=0)[::100] \n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "x = da.random.normal(10, 0.1, size=(20000, 20000), chunks=(1000, 1000))\n",
    "y = x.mean(axis=0)[::100] \n",
    "y.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dask Dataframes\n",
    "\n",
    "meant to mimick most of pandas dataframes, but now these dataframes can be out of core."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lah ../01_Plotting_and_Viz/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df = pd.read_csv(\"../01_Plotting_and_Viz/data/uber-raw-data-apr14.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df = dd.read_csv(\"../01_Plotting_and_Viz/data/uber-raw-data-apr14.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the reading in is delayed, but we can still inspect the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other operations are delayed until you compute them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()['Lat'].compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use distributed dataframes to analyze NYC Taxi data stored as CSV files on S3.\n",
    "This data is stored as large CSV files on S3 in a public bucket.\n",
    "\n",
    "(https://github.com/mrocklin/scipy-2016-parallel/blob/master/notebooks/08-distributed-dataframes.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install s3fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from s3fs import S3FileSystem\n",
    "s3 = S3FileSystem(anon=True)\n",
    "\n",
    "s3.ls('dask-data/nyc-taxi/2015')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to load this data with Pandas, but there is too much data here to fit in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.info('dask-data/nyc-taxi/2015/yellow_tripdata_2015-01.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "with s3.open('dask-data/nyc-taxi/2015/yellow_tripdata_2015-01.csv') as f:\n",
    "    df = pd.read_csv(f, nrows=5)  # look at just five rows\n",
    "    \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, progress\n",
    "\n",
    "e = Client(set_as_default=True)\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "df = dd.read_csv('s3://dask-data/nyc-taxi/2015/yellow_tripdata_2015-01.csv',\n",
    "                 parse_dates=['tpep_pickup_datetime', 'tpep_dropoff_datetime'],\n",
    "                 storage_options={'anon': True})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = e.persist(df)\n",
    "progress(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existing Pandas experience transfers over decently well to Dask.dataframe. However there are a few caveats when dealing with distributed systems:\n",
    "   - Until you call e.persist (for large results) or e.compute (for small results), all computations are lazy\n",
    "   - Call progress on a dataframe after you persist to track the progress of a computation. You can continue doing work immediately. All work happens in the background.\n",
    "   - If you are computing a small result, just add .compute() to the end of your result, like df.passenger_count.sum().compute(). This will block and return the result when finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_fares = df[df.fare_amount > 0]\n",
    "fares = df[['fare_amount', 'tip_amount', 'payment_type']]\n",
    "\n",
    "fares = e.persist(fares)  # triggers computation\n",
    "progress(fares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fares.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(fares.tip_amount == 0).sum().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fares.count().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.passenger_count.sum().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, we connect to the cluster and use dask.dataframe to load the CSV data into ~700 Pandas dataframes spread across our cluster. We get back a Dask.dataframe to coordinate these small Pandas dataframes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`dask.delayed` (a la joblib):\n",
    " \n",
    "   - `delayed(function)(*args, **kwargs)` -> lazy function that hasn't yet been evaluated\n",
    "   - `delayed(data)` -> lazy object that pretends to be your data\n",
    " \n",
    " See the excellent talk at SciPy 2016: https://www.youtube.com/watch?v=PAGjm4BMKlk&list=PLYx7XA2nY5Gf37zYZMw6OqGFRPjB1jCy6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a local Executor client\n",
    "from distributed import Client\n",
    "Client(set_as_default=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from dask import delayed, visualize\n",
    "from time import sleep\n",
    "\n",
    "@delayed(pure=True)\n",
    "def add(a,b):\n",
    "    sleep(random.random())\n",
    "    return a+b\n",
    "\n",
    "@delayed(pure=True)\n",
    "def mul(a,b):\n",
    "    sleep(random.random())\n",
    "    return a*b\n",
    "\n",
    "@delayed(pure=True)\n",
    "def inc(a):\n",
    "    sleep(random.random())\n",
    "    return a + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = add(1,2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = inc(1)\n",
    "b = mul(1,2)\n",
    "c = add(a,b)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.visualize(rankdir=\"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for x in range(4):\n",
    "    a = inc(1)\n",
    "    b = mul(1,x)\n",
    "    c = add(a,b)\n",
    "    results.append(c)\n",
    "\n",
    "total = delayed(sum,pure=True)(results)\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total.visualize(rankdir=\"LR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pure=True`: finds nested shared expressions deep in code that dont need to be recomputed. Eg. `inc(1)` here is the same so it only gets called once. A pure function should have no side-effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for y in range(2,10,2):\n",
    "    for x in range(4):\n",
    "        a = inc(1)\n",
    "        b = mul(y,x)\n",
    "        c = add(a,b)\n",
    "        results.append(c)\n",
    "\n",
    "total = delayed(sum,pure=True)(results)\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tree reduction --- add up pairwise\n",
    "while len(results) > 1:\n",
    "    new_results = []\n",
    "    \n",
    "    for i in range(0,len(results),2):\n",
    "        res = add(results[i], results[i+1])\n",
    "        new_results.append(res)\n",
    "    \n",
    "    results = new_results\n",
    "\n",
    "total = results[0]\n",
    "total.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: you cannot iterate over a delayed object and you can't use them in case statements (because we dont know how long they are until they've been computed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(inc(1)):\n",
    "    print(\"hey!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scheduling the execution\n",
    "\n",
    "where you run a certain piece of a parallel task depends on your architecture, what needs each piece has, and what the bottlenecks are in moving data between pieces.\n",
    "\n",
    "The **single machine scheduler** is optimizes for larger-than-memory use. It uses:\n",
    "  \n",
    "   - Parallel CPU\n",
    "   - Minimizes RAM: tries to remove intermediary tasks that aren't needed anymore\n",
    "   - low overhead: 100$\\mu$s per task\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Distributed scheduler** - tries to minimize data movement so you dont have to move data between computers unnecessarily.\n",
    " \n",
    " - distributed to schedule across many workers\n",
    " - works well with distributed datastores (HDFS)\n",
    " - asynchronous\n",
    " - data local\n",
    " \n",
    "run `dask-scheduler` on the command line and then "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, progress\n",
    "e = Client(set_as_default=True)\n",
    "e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# swap out concurrent.futures with a dask executor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile slowfunc.py\n",
    "from time import sleep\n",
    "\n",
    "def slowfunc(x,y,delay=1):\n",
    "    sleep(delay)\n",
    "    return(x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from slowfunc import slowfunc\n",
    "futures = [e.submit(slowfunc,1,2, delay=1) for _ in range(100)]\n",
    "[f.result() for f in futures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "There are loads of ways to do mapping now in Python, [this notebook](https://github.com/mrocklin/scipy-2016-parallel/blob/master/notebooks/map-rosetta-stone.ipynb) is the Rosetta stone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "   You can also use MPI with Dask...see <a href=\"http://mpi.dask.org/en/latest/install.html\">dask_mpi</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://jax.readthedocs.io/en/latest/_static/jax_logo_250px.png\">\n",
    "\n",
    "Jax is accelerated numpy (and more): https://jax.readthedocs.io/en/latest/jax-101/01-jax-basics.html\n",
    "\n",
    "We'll see more of jax when we do ML, since it also provides automatic differentiation for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = jnp.arange(10)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_devices = jax.local_device_count() \n",
    "n_devices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JAX uses the XLA compiler under the hood, and enables you to just-in-time (jit) compile your code to make it faster and more efficient. This is the purpose of the @jit annotation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import numpy as jnp, random\n",
    "\n",
    "def selu(x, alpha=1.67, lmbda=1.05):\n",
    "    return lmbda * jnp.where(x > 0, x, alpha * jnp.exp(x) - alpha)\n",
    "\n",
    "v = random.normal(random.PRNGKey(42), (1000000,))\n",
    "%timeit selu(v).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "\n",
    "selu_jit = jax.jit(selu)\n",
    "%timeit selu_jit(v).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_vector = jnp.arange(int(1e7))\n",
    "\n",
    "%timeit jnp.dot(long_vector, long_vector).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try this on a GPU and TPU in [Google Colab](https://colab.research.google.com/github/profjsb/python-seminar/blob/master/DataFiles_and_Notebooks/04_Parallelism/02_dask_and_jax.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import jax.tools.colab_tpu\n",
    "    jax.tools.colab_tpu.setup_tpu()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_vector = jnp.arange(int(1e7))\n",
    "\n",
    "%timeit jnp.dot(long_vector, long_vector).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
